# 논문 요약: The AI Divide

## 한 줄 요약
미국인이 AI를 바라보는 방식은 하나가 아니라 네 가지이고, 어떤 유형에 속하는지는 교육·소득·인종에 의해 결정된다.

---

## 문제 제기

대부분의 여론조사는 "미국인의 52%가 AI에 대해 우려한다"처럼 하나의 숫자로 보도합니다. 그런데 이 52% 안에는 전혀 다른 사람들이 섞여 있습니다:

- AI가 뭔지 **아예 모르는** 사람
- AI를 잘 알면서 **무서워하는** 사람
- AI를 잘 알면서 **좋아하는** 사람
- AI에 대해 **분야에 따라 다르게** 생각하는 사람

이들을 하나의 숫자로 뭉뚱그리면, 실제로 누가 AI 정책 논의에서 소외되고 있는지 보이지 않습니다.

---

## 이론: 3단계 AI 격차

인터넷 초기에 "접속이 되느냐" → "잘 쓸 수 있느냐" → "실질적 혜택을 받느냐"로 디지털 격차가 진화했듯이, AI에 대한 태도도 3단계로 나뉩니다:

1. **AI가 뭔지 아는가?** (인식 격차)
2. **분야별로 다르게 판단할 수 있는가?** (태도 복잡성 격차)
3. **구체적 영역에서 도움/해가 된다고 보는가?** (결과 격차)

핵심 주장: 1단계를 넘지 못하면 2단계, 3단계로 갈 수 없습니다. "AI가 뭔지 모르면 의견 자체가 불가능하다."

---

## 데이터와 방법

- Pew Research Center 2023년 8월 조사, 미국 성인 **10,749명**
- 응답자를 무작위로 두 그룹(Form A, B)으로 나눠 서로 다른 질문을 배정 → 같은 유형이 나오면 신뢰성 확인
- **잠재계층분석(LCA):** 비슷한 응답 패턴을 가진 사람들을 자동으로 묶어주는 통계 기법

---

## 결과 1: 네 가지 유형

| 유형 | 비율 | 특징 | 한마디 |
|---|---|---|---|
| **AI-Anxious** | 9% | AI를 잘 알지만 거의 모든 분야에서 해롭다고 봄 | "알아서 두려운 사람" |
| **AI-Uninformed** | 33% | AI를 거의 모름, 그런데 해롭다는 응답도 거의 없음 | "모르니까 걱정도 없는 사람" |
| **AI-Advantaged** | 21% | AI를 잘 알고, 거의 모든 분야에서 긍정적 | "알아서 편한 사람" |
| **AI-Ambivalent** | 37% | 중간 정도 인식, 건강·안전은 긍정이나 고객서비스·정보는 부정 | "따져보고 판단하는 사람" |

두 그룹(Form A, B)에서 같은 네 유형이 나왔습니다 → 특정 질문 때문이 아니라 실제로 존재하는 유형입니다.

---

## 결과 2: 누가 어디에 속하는가

- **교육이 낮을수록** → Uninformed이나 Anxious에 속할 확률 높음
- **소득이 높을수록** → Advantaged에 속할 확률 높음
- 그런데 이 효과의 대부분은 "AI를 아느냐"를 거쳐서 작동합니다
  - 교육 → AI를 알게 됨 → Advantaged에 속함
  - 저학력 → AI를 모름 → Uninformed에 속함
- AI 인식의 영향력은 다른 예측변수의 약 17배

---

## 결과 3: 인종에 따라 교육의 효과가 다르다

같은 고졸이라도:
- **흑인 고졸자**가 Anxious에 속할 확률은 **백인 고졸자의 약 3배**
- 이유로 추정: 범죄예측 알고리즘, 복지심사 자동화 등 AI를 처벌적 맥락에서 먼저 경험했을 가능성

---

## 결과 4: 민감도 분석 — 가장 중요한 발견

"AI 인식" 항목을 분류에서 빼고 다시 분석하면?

→ **4개 유형이 3개로 줄어듭니다.** Uninformed과 Advantaged가 합쳐집니다.

왜? 이 두 그룹은 "AI가 건강에 도움이 될까?" 같은 구체적 질문에 비슷하게 대답했습니다. 차이는 오직 AI가 뭔지 아느냐뿐이었습니다. 그 정보를 빼면 구분이 사라집니다.

**이것이 의미하는 바:**
- "AI가 뭔지 안다"는 것이 단순한 배경 정보가 아니라, 유형 자체를 만들어내는 핵심 요소
- 논문의 이론("인식이 없으면 복잡한 태도도 없다")이 데이터로 직접 확인됨

---

## 결과 5: 2022-2024 시간에 따른 변화

- 2022년 말: 낙관적 vs 중립 (ChatGPT 출시 직전)
- 2023-2024년: 회의적 vs 중립 (ChatGPT 이후)

내용은 낙관→회의로 바뀌었지만, "많이 아는 사람 vs 적게 아는 사람"이라는 구조는 동일. AI 격차는 "좋아하느냐 싫어하느냐"가 아니라 "관여하느냐 안 하느냐"의 격차입니다.

---

## 정책 함의

- 미국인 3명 중 1명(Uninformed)은 AI에 대한 의견을 형성할 재료 자체가 없음 → AI 거버넌스 논의에서 사실상 배제
- AI 리터러시 교육이 이 격차를 줄일 수 있지만, 흑인·히스패닉 커뮤니티에는 맞춤형 접근 필요
- "무지한 사람에게 정보를 주면 된다"는 단순한 접근은 위험 — 이들의 무관심이 구조적 배제와 불신에서 비롯될 수 있기 때문

---

## 한계

- 횡단면 데이터라 "교육 → 인식 → 유형"의 인과관계를 확정할 수 없음
- 온라인 패널이라 디지털 접근이 가장 낮은 사람들이 과소대표될 수 있음
- 인식이 분류 기준이면서 예측변수 — 민감도 분석으로 투명하게 다뤘으나 한계는 존재

---

*생성일: 2026-02-24*
