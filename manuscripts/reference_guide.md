# Reference Guide: AI Attitude Polarization Papers

**Papers covered:**
- Paper 1: "Occupational Identity Threat and AI Attitude Polarization" (HRDQ / Personnel Review)
- Paper 2: "Epistemic Cognition and AI Attitudes: Beyond the Information Deficit" (HRDI / Adult Education Quarterly)

**Total unique references: 67**
**File:** `references.bib`

---

## Section 1: Occupational / Professional Identity Theory

| Citation Key | Reference | How Used |
|---|---|---|
| `petriglieri2011` | Petriglieri, J.L. (2011). Under Threat: Responses to and the Consequences of Threats to Individuals' Identities. *Academy of Management Review*, 36(4), 641–662. | Core theoretical framework for Paper 1; defines identity threat and its antecedents, responses, and consequences. |
| `ashforth1999` | Ashforth, B.E. & Kreiner, G.E. (1999). "How Can You Do It?": Dirty Work and the Challenge of Constructing a Positive Identity. *Academy of Management Review*, 24(3), 413–434. | Foundational occupational identity theory showing how workers actively construct and defend positive identities under stigma. |
| `kreiner2006` | Kreiner, G.E., Hollensbe, E.C. & Sheep, M.L. (2006). Where Is the "Me" Among the "We"? Identity Work and the Search for Optimal Balance. *Academy of Management Journal*, 49(5), 1031–1057. | Establishes identity work tactics people use to maintain occupational identity in demanding roles. |
| `conroy2014` | Conroy, S.A. & O'Leary-Kelly, A.M. (2014). Letting Go and Moving On: Work-Related Identity Loss and Recovery. *Academy of Management Review*, 39(1), 67–87. | Theoretical model of work-related identity loss directly applicable to AI-induced job displacement threat. |
| `grote2009` | Grote, G. & Raeder, S. (2009). Careers and Identity in Flexible Working: Do Flexible Identities Fare Better? *Human Relations*, 62(2), 219–244. | Empirical evidence linking career flexibility to identity adaptation; contextualizes AI disruption within broader flexible work trends. |
| `pratt2006` | Pratt, M.G., Rockmann, K.W. & Kaufmann, J.B. (2006). Constructing Professional Identity: The Role of Work and Identity Learning Cycles. *Academy of Management Journal*, 49(2), 235–262. | Shows how identity construction is triggered by work–identity integrity violations, relevant to AI replacing professional tasks. |
| `ibarra1999` | Ibarra, H. (1999). Provisional Selves: Experimenting with Image and Identity in Professional Adaptation. *Administrative Science Quarterly*, 44(4), 764–791. | Documents how professionals experiment with new identities during transitions; relevant to AI-forced role change. |
| `caza2009` | Caza, B.B. & Wilson, M.G. (2009). Me, Myself, and I: The Benefits of Work-Identity Complexity. In Roberts & Dutton (Eds.), *Exploring Positive Identities and Organizations* (pp. 99–125). Routledge. | Argues work-identity complexity buffers against identity threats; supports heterogeneity in AI attitude responses. |

---

## Section 2: Loss Aversion / Prospect Theory

| Citation Key | Reference | How Used |
|---|---|---|
| `kahneman1979` | Kahneman, D. & Tversky, A. (1979). Prospect Theory: An Analysis of Decision under Risk. *Econometrica*, 47(2), 263–291. | Foundational prospect theory framework; establishes loss aversion as core mechanism driving asymmetric responses to AI threat. |
| `thaler1980` | Thaler, R.H. (1980). Toward a Positive Theory of Consumer Choice. *Journal of Economic Behavior & Organization*, 1(1), 39–60. | Extends loss aversion to everyday decision contexts; supports argument that perceived job threat amplifies AI negativity. |
| `novemsky2005` | Novemsky, N. & Kahneman, D. (2005). The Boundaries of Loss Aversion. *Journal of Marketing Research*, 42(2), 119–128. | Clarifies when loss aversion operates; informs conditions under which occupational threat triggers negative AI attitudes. |
| `tom2007` | Tom, S.M., Fox, C.R., Trepel, C. & Poldrack, R.A. (2007). The Neural Basis of Loss Aversion in Decision-Making Under Risk. *Science*, 315(5811), 515–518. | Neuroimaging evidence for loss aversion; strengthens theoretical claim that threat perception is a robust psychological mechanism. |
| `ert2013` | Ert, E. & Erev, I. (2013). On the Descriptive Value of Loss Aversion in Decisions under Risk: Six Clarifications. *Judgment and Decision Making*, 8(3), 214–235. | Nuances when loss aversion predicts behavior; used to qualify scope conditions of the identity-threat hypothesis. |

---

## Section 3: AI Attitudes / Public Opinion on AI

| Citation Key | Reference | How Used |
|---|---|---|
| `pew2022` | Pew Research Center (2022, March). *How Americans Think About Artificial Intelligence*. | Descriptive baseline data on American AI attitudes by demographic subgroups used in Paper 1 analysis. |
| `pew2023` | Pew Research Center (2023, August). *Growing Public Concern About the Role of AI in Daily Life*. | Documents rising concern trend (38% to 52% net-concerned); motivates the polarization research question. |
| `pew2024` | Pew Research Center (2024, September). *Concern Over the Impact of AI on 2024 Presidential Campaign*. | Shows partisan dimension of AI concern in election context; supports political polarization framing. |
| `zhang2019` | Zhang, B. & Dafoe, A. (2019). *Artificial Intelligence: American Attitudes and Trends*. Oxford: Centre for the Governance of AI. | Nationally representative baseline survey of AI attitudes; key prior study against which Paper 1 findings are compared. |
| `neudert2020` | Neudert, L.-M., Knuutila, A. & Howard, P.N. (2020). *Global Attitudes Towards AI, Machine Learning & Automated Decision Making*. OxCAIGG. | Cross-national AI attitude data; contextualizes US findings in Paper 1 within global patterns. |
| `cave2019` | Cave, S. & Dihal, K. (2019). Hopes and Fears for Intelligent Machines in Fiction and Reality. *Nature Machine Intelligence*, 1, 74–78. | Analyzes narrative framing of AI; provides cultural context for why AI attitudes cluster around hope/fear dimensions. |
| `kieslich2022` | Kieslich, K., Keller, B. & Starke, C. (2022). Artificial Intelligence Ethics by Design. *Big Data & Society*, 9(1). | Public perception of ethical AI principles; informs discussion of how different groups prioritize AI concerns. |
| `schiff2024` | Schiff, D. (2024). *The Politics of AI: Will Bipartisanship Last or Is Polarization Inevitable?* Yale ISPS Working Paper. | Directly addresses political polarization in AI policymaking; key theoretical anchor for partisan AI attitude differences. |

---

## Section 4: Political Polarization & Technology

| Citation Key | Reference | How Used |
|---|---|---|
| `kahan2012` | Kahan, D.M. et al. (2012). The Polarizing Impact of Science Literacy and Numeracy on Perceived Climate Change Risks. *Nature Climate Change*, 2(10), 732–735. | Demonstrates science literacy can increase, not decrease, polarization; key analogy for AI attitude polarization argument. |
| `druckman2013` | Druckman, J.N., Peterson, E. & Slothuus, R. (2013). How Elite Partisan Polarization Affects Public Opinion Formation. *American Political Science Review*, 107(1), 57–79. | Elite cueing mechanism explains how partisan signals shape mass AI attitudes; supports top-down polarization hypothesis. |
| `bolsen2014` | Bolsen, T., Druckman, J.N. & Cook, F.L. (2014). The Influence of Partisan Motivated Reasoning on Public Opinion. *Political Behavior*, 36(2), 235–262. | Partisan motivated reasoning framework; explains why political identity moderates AI attitude formation. |
| `zaller1992` | Zaller, J.R. (1992). *The Nature and Origins of Mass Opinion*. Cambridge University Press. | RAS model of opinion formation; theoretical foundation for how partisan elites shape mass AI attitudes. |
| `guess2020` | Guess, A.M., Nyhan, B. & Reifler, J. (2020). Exposure to Untrustworthy Websites in the 2016 US Election. *Nature Human Behaviour*, 4, 472–480. | Evidence on partisan information exposure patterns; contextualizes differential AI information environments by party. |
| `bail2018` | Bail, C.A. et al. (2018). Exposure to Opposing Views on Social Media Can Increase Political Polarization. *PNAS*, 115(37), 9216–9221. | Counterintuitive finding that cross-cutting exposure amplifies polarization; relevant to AI information exposure effects. |

---

## Section 5: AI and Workforce / Organizations

| Citation Key | Reference | How Used |
|---|---|---|
| `brynjolfsson2014` | Brynjolfsson, E. & McAfee, A. (2014). *The Second Machine Age*. W.W. Norton. | Canonical account of AI-driven labor market transformation; foundational context for occupational identity threat argument. |
| `frey2017` | Frey, C.B. & Osborne, M.A. (2017). The Future of Employment: How Susceptible Are Jobs to Computerisation? *Technological Forecasting and Social Change*, 114, 254–280. | Estimates 47% US jobs at high computerization risk; key empirical basis for occupational threat operationalization. |
| `acemoglu2020` | Acemoglu, D. & Restrepo, P. (2020). Robots and Jobs: Evidence from US Labor Markets. *Journal of Political Economy*, 128(6), 2188–2244. | Causal evidence that automation reduces employment and wages; supports objective occupational threat measures. |
| `autor2015` | Autor, D.H. (2015). Why Are There Still So Many Jobs? *Journal of Economic Perspectives*, 29(3), 3–30. | Reviews task-based framework of automation; nuances occupational threat with task complementarity argument. |
| `arntz2016` | Arntz, M., Gregory, T. & Zierahn, U. (2016). *The Risk of Automation for Jobs in OECD Countries*. OECD Working Paper No. 189. | Task-level analysis finds lower automation risk than Frey & Osborne; used to address measurement debates. |
| `makridakis2017` | Makridakis, S. (2017). The Forthcoming AI Revolution: Its Impact on Society and Firms. *Futures*, 90, 46–60. | Broad analysis of AI societal impacts; provides context for why AI attitudes are multidimensional. |
| `jarrahi2018` | Jarrahi, M.H. (2018). Artificial Intelligence and the Future of Work: Human-AI Symbiosis in Organizational Decision Making. *Business Horizons*, 61(4), 577–586. | Human-AI collaboration framework; informs discussion of how occupational roles are transformed rather than eliminated. |
| `parker2022` | Parker, S.K. & Grote, G. (2022). Automation, Algorithms, and Beyond: Why Work Design Matters More Than Ever. *Applied Psychology*, 71(4), 1171–1204. | Work design perspective on automation; bridges AI adoption and occupational identity in organizational contexts. |

---

## Section 6: HRD / Workforce Development

| Citation Key | Reference | How Used |
|---|---|---|
| `swanson2009` | Swanson, R.A. & Holton, E.F. (2009). *Foundations of Human Resource Development* (2nd ed.). Berrett-Koehler. | Establishes HRD theoretical foundations; situates Paper 1 within the field's scholarly tradition. |
| `torraco2005` | Torraco, R.J. (2005). Work Design Theory: A Review and Critique with Implications for HRD. *Human Resource Development Quarterly*, 16(1), 85–109. | Links work design to HRD practice; justifies HRD intervention implications in the discussion section. |
| `ellinger2014` | Ellinger, A.E. & Ellinger, A.D. (2014). Leveraging HRD Expertise to Improve Supply Chain Managers' Skills. *European Journal of Training and Development*, 38(1/2), 118–135. | Demonstrates HRD's role in upskilling for technological change; applied example for AI readiness interventions. |
| `alagaraja2003` | Alagaraja, M. & Dooley, L.M. (2003). Origins and Historical Influences on HRD: A Global Perspective. *Human Resource Development Review*, 2(1), 82–96. | Historical grounding of HRD as a field; establishes scholarly context for Paper 1's HRD journal contribution. |
| `hamlin2011` | Hamlin, B. & Stewart, J. (2011). What Is HRD? A Definitional Review and Synthesis. *Journal of European Industrial Training*, 35(3), 199–220. | Definitional clarity on HRD domain; supports framing of AI attitude change as an HRD challenge. |

---

## Section 7: Methods

| Citation Key | Reference | How Used |
|---|---|---|
| `lumley2004` | Lumley, T. (2004). Analysis of Complex Survey Samples. *Journal of Statistical Software*, 9(8), 1–19. | Primary citation for the R `survey` package used for Pew complex survey data analysis in both papers. |
| `lumley2010` | Lumley, T. (2010). *Complex Surveys: A Guide to Analysis Using R*. Wiley. | Methodological reference for design-based inference procedures applied to Pew survey data. |
| `fairlie2005` | Fairlie, R.W. (2005). An Extension of the Blinder-Oaxaca Decomposition Technique to Logit and Probit Models. *Journal of Economic and Social Measurement*, 30(4), 305–316. | Decomposition method used in Paper 1 to partition AI attitude gaps between occupational groups. |
| `mize2019` | Mize, T.D. (2019). Best Practices for Estimating, Interpreting, and Presenting Nonlinear Interaction Effects. *Sociological Science*, 6, 81–117. | Guides correct interpretation of interaction effects in logistic regression models in both papers. |
| `mood2010` | Mood, C. (2010). Logistic Regression: Why We Cannot Do What We Think We Can Do. *European Sociological Review*, 26(1), 67–82. | Addresses rescaling problems in cross-group logit comparisons; informs analytical choices in both papers. |
| `allison1999` | Allison, P.D. (1999). Comparing Logit and Probit Coefficients Across Groups. *Sociological Methods & Research*, 28(2), 186–208. | Technical guidance on cross-group comparisons of binary outcome models used in decomposition analyses. |

---

## Section 8: Epistemic Cognition / Reflective Judgment

| Citation Key | Reference | How Used |
|---|---|---|
| `king1994` | King, P.M. & Kitchener, K.S. (1994). *Developing Reflective Judgment*. Jossey-Bass. | Core theoretical framework for Paper 2; defines seven-stage model of epistemic development applied to AI attitude formation. |
| `kuhn1991` | Kuhn, D. (1991). *The Skills of Argument*. Cambridge University Press. | Empirical study of informal reasoning; supports argument that epistemic skills predict quality of AI risk evaluation. |
| `perry1970` | Perry, W.G. (1970). *Forms of Intellectual and Ethical Development in the College Years*. Holt, Rinehart & Winston. | Foundational developmental epistemology model; provides intellectual lineage for Paper 2's theoretical framework. |
| `baxtermagolda2001` | Baxter Magolda, M.B. (2001). *Making Their Own Way*. Stylus. | Self-authorship theory shows how epistemic development enables independent AI risk judgment. |
| `hofer1997` | Hofer, B.K. & Pintrich, P.R. (1997). The Development of Epistemological Theories. *Review of Educational Research*, 67(1), 88–140. | Comprehensive review of epistemological beliefs research; grounds Paper 2's measurement approach. |
| `bendixen2004` | Bendixen, L.D. & Rule, D.C. (2004). An Integrative Approach to Personal Epistemology. *Educational Psychologist*, 39(1), 69–80. | Integrative model identifies epistemic doubt and volition as change mechanisms relevant to AI literacy interventions. |
| `bromme2010` | Bromme, R., Kienhues, D. & Porsch, T. (2010). Who Knows What and Who Can We Believe? In Bendixen & Feucht (Eds.), *Personal Epistemology in the Classroom* (pp. 163–193). Cambridge UP. | Epistemic beliefs about knowledge from others; directly relevant to how people evaluate expert AI claims. |
| `barzilai2018` | Barzilai, S. & Chinn, C.A. (2018). On the Goals of Epistemic Education. *Journal of the Learning Sciences*, 27(3), 353–389. | Defines apt epistemic performance as the educational goal; frames Paper 2's implications for AI literacy education. |

---

## Section 9: Knowledge Gap Hypothesis

| Citation Key | Reference | How Used |
|---|---|---|
| `tichenor1970` | Tichenor, P.J., Donohue, G.A. & Olien, C.N. (1970). Mass Media Flow and Differential Growth in Knowledge. *Public Opinion Quarterly*, 34(2), 159–170. | Original knowledge gap hypothesis; foundational theory that higher SES groups gain AI knowledge faster, widening gaps. |
| `bonfadelli2002` | Bonfadelli, H. (2002). The Internet and Knowledge Gaps. *European Journal of Communication*, 17(1), 65–84. | Updates knowledge gap for the internet era; shows digital access alone does not close knowledge gaps. |
| `viswanath1996` | Viswanath, K. & Finnegan, J.R. (1996). The Knowledge Gap Hypothesis: Twenty-Five Years Later. In Burleson (Ed.), *Communication Yearbook 19* (pp. 187–227). Sage. | Comprehensive review and refinement of knowledge gap theory; establishes moderating conditions for Paper 2. |
| `gaziano1997` | Gaziano, C. (1997). Forecast 2000: Widening Knowledge Gaps. *Journalism & Mass Communication Quarterly*, 74(2), 237–264. | Projects future knowledge gap widening; motivates Paper 2's concern about AI knowledge inequality. |
| `hwang2009` | Hwang, Y. & Jeong, S.-H. (2009). Revisiting the Knowledge Gap Hypothesis: A Meta-Analysis of 35 Years of Research. *Journalism & Mass Communication Quarterly*, 86(3), 513–532. | Meta-analytic support for knowledge gap; confirms SES-based AI knowledge gaps are expected and systematic. |

---

## Section 10: AI Literacy / Digital Literacy

| Citation Key | Reference | How Used |
|---|---|---|
| `long2020` | Long, D. & Magerko, B. (2020). What Is AI Literacy? *Proceedings of CHI 2020* (pp. 1–16). ACM. | Defines AI literacy competencies; provides conceptual framework for measuring AI literacy in Paper 2. |
| `ng2021` | Ng, D.T.K., Leung, J.K.L., Chu, S.K.W. & Qiao, M.S. (2021). Conceptualizing AI Literacy. *Computers and Education: Artificial Intelligence*, 2, 100041. | Systematic review of AI literacy frameworks; supports operationalization of AI knowledge in Paper 2. |
| `selwyn2022` | Selwyn, N. (2022). The Future of AI and Education: Some Cautionary Notes. *European Journal of Education*, 57(4), 620–631. | Critical perspective on AI in education; provides counterpoint for discussing limitations of AI literacy interventions. |
| `laupichler2022` | Laupichler, M.C., Aster, A., Schirch, J. & Raupach, T. (2022). AI Literacy in Higher and Adult Education. *Computers and Education: Artificial Intelligence*, 3, 100101. | Scoping review of AI literacy in adult contexts; directly relevant to Paper 2's adult education implications. |
| `hargittai2002` | Hargittai, E. (2002). Second-Level Digital Divide: Differences in People's Online Skills. *First Monday*, 7(4). | Distinguishes access from skills in digital divides; supports distinction between AI exposure and AI understanding. |
| `vandijk2020` | van Dijk, J. (2020). *The Digital Divide*. Polity Press. | Comprehensive digital divide framework; grounds Paper 2's argument that AI attitude gaps reflect deeper digital inequalities. |

---

## Section 11: Adult Education / Transformative Learning

| Citation Key | Reference | How Used |
|---|---|---|
| `mezirow1991` | Mezirow, J. (1991). *Transformative Dimensions of Adult Learning*. Jossey-Bass. | Core transformative learning theory; Paper 2 argues AI exposure can trigger perspective transformation in adults. |
| `mezirow2000` | Mezirow, J. & Associates (2000). *Learning as Transformation*. Jossey-Bass. | Updated transformation theory with multiple contributors; provides richer account of transformative learning process. |
| `cranton2006` | Cranton, P. (2006). *Understanding and Promoting Transformative Learning* (2nd ed.). Jossey-Bass. | Practical guide to fostering transformative learning; informs Paper 2's implications for AI education practice. |
| `freire1970` | Freire, P. (1970). *Pedagogy of the Oppressed*. Herder and Herder. | Critical pedagogy foundation; supports Paper 2's argument for empowering marginalized groups through AI literacy. |
| `knowles1980` | Knowles, M.S. (1980). *The Modern Practice of Adult Education* (2nd ed.). Cambridge Adult Education. | Andragogy principles; grounds Paper 2's adult learning framework for AI literacy interventions. |
| `merriam2007` | Merriam, S.B., Caffarella, R.S. & Baumgartner, L.M. (2007). *Learning in Adulthood* (3rd ed.). Jossey-Bass. | Comprehensive adult learning survey; contextualizes epistemic development within broader adult learning theory. |
| `jarvis2006` | Jarvis, P. (2006). *Towards a Comprehensive Theory of Human Learning*. Routledge. | Situates epistemic change within experiential learning theory; supports Paper 2's developmental perspective. |

---

## Section 12: Risk Perception

| Citation Key | Reference | How Used |
|---|---|---|
| `kasperson1988` | Kasperson, R.E. et al. (1988). The Social Amplification of Risk: A Conceptual Framework. *Risk Analysis*, 8(2), 177–187. | Social amplification framework explains how media and social networks amplify AI risk perceptions differentially. |
| `slovic1987` | Slovic, P. (1987). Perception of Risk. *Science*, 236(4799), 280–285. | Psychometric risk perception paradigm; establishes dread/unknown dimensions relevant to AI threat perception. |
| `scheufele2005` | Scheufele, D.A. & Lewenstein, B.V. (2005). The Public and Nanotechnology: How Citizens Make Sense of Emerging Technologies. *Journal of Nanoparticle Research*, 7(6), 659–667. | Emerging technology risk perception model; provides direct analogy for how publics make sense of AI risks. |
| `kahlor2006` | Kahlor, L.A., Dunwoody, S., Griffin, R.J. & Neuwirth, K. (2006). Seeking and Processing Information About Impersonal Risk. *Science Communication*, 28(2), 163–194. | Risk Information Seeking and Processing (RISP) model; explains why high-threat individuals seek more AI information. |

---

## Cross-Reference: Which Paper Uses Which Reference

**Paper 1 only (Occupational Identity Threat):**
`petriglieri2011`, `ashforth1999`, `kreiner2006`, `conroy2014`, `grote2009`, `pratt2006`, `ibarra1999`, `caza2009`, `kahneman1979`, `thaler1980`, `novemsky2005`, `tom2007`, `ert2013`, `swanson2009`, `torraco2005`, `ellinger2014`, `alagaraja2003`, `hamlin2011`, `fairlie2005`

**Paper 2 only (Epistemic Cognition):**
`king1994`, `kuhn1991`, `perry1970`, `baxtermagolda2001`, `hofer1997`, `bendixen2004`, `bromme2010`, `barzilai2018`, `tichenor1970`, `bonfadelli2002`, `viswanath1996`, `gaziano1997`, `hwang2009`, `long2020`, `ng2021`, `selwyn2022`, `laupichler2022`, `hargittai2002`, `vandijk2020`, `mezirow1991`, `mezirow2000`, `cranton2006`, `freire1970`, `knowles1980`, `merriam2007`, `jarvis2006`, `kasperson1988`, `slovic1987`, `scheufele2005`, `kahlor2006`

**Shared by both papers:**
`pew2022`, `pew2023`, `pew2024`, `zhang2019`, `neudert2020`, `cave2019`, `kieslich2022`, `schiff2024`, `kahan2012`, `druckman2013`, `bolsen2014`, `zaller1992`, `guess2020`, `bail2018`, `brynjolfsson2014`, `frey2017`, `acemoglu2020`, `autor2015`, `arntz2016`, `makridakis2017`, `jarrahi2018`, `parker2022`, `lumley2004`, `lumley2010`, `mize2019`, `mood2010`, `allison1999`

---

*Last updated: 2026-02-22*
